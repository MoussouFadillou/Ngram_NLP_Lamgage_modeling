{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Moussou_ngram_lms.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8188ad2139a046339eec575e3758cde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae3357a3d4014104ab6fa5924ddba0b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7591c1e23a5b4a2aaf4b990483a4df0d",
              "IPY_MODEL_7c7caeea1f71413f9366b29764a8c2fb"
            ]
          }
        },
        "ae3357a3d4014104ab6fa5924ddba0b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7591c1e23a5b4a2aaf4b990483a4df0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a4a2711ba7684b0e98add041c2034f35",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 133176,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 133176,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e883a942c39243b3b3c351e7ecf0c29a"
          }
        },
        "7c7caeea1f71413f9366b29764a8c2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99e06b0d12904edd8b89a5f3f3d39def",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 133176/133176 [00:00&lt;00:00, 577293.00it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4982c7056add4b87a364b32a5da703e2"
          }
        },
        "a4a2711ba7684b0e98add041c2034f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e883a942c39243b3b3c351e7ecf0c29a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99e06b0d12904edd8b89a5f3f3d39def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4982c7056add4b87a364b32a5da703e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUj9YCXHoixW"
      },
      "source": [
        "# N-Gram Language Modeling\n",
        "\n",
        "In **language modeling** we want to model the probability of variable length sequences, $$\\large p(w_1,\\ldots,w_T)=\\prod_{t=1}^T p(w_t|w_{<t}).$$\n",
        "\n",
        "An **n-gram language model** assumes that each word $w_t$ only depends on the preceding $n-1$ words, $$\\large p(w_1,\\ldots,w_T)=\\prod_{t=1}^T p(w_t|w_{t-n+1},\\ldots,w_{t-1}).$$\n",
        "\n",
        " \n",
        "\n",
        "#### Example\n",
        "For instance, when modeling the sentence $$\\texttt{the cat sat on the mat .}$$ a 3-gram language model assumes that $$p(\\texttt{mat}|\\texttt{the cat sat on the}) \\approx p(\\texttt{mat}|\\texttt{on the}).$$\n",
        "\n",
        "The sub-sequence $(\\texttt{on the mat})$ is a *3-gram* or *trigram*.\n",
        "\n",
        "### Count-based Estimation\n",
        "\n",
        "Given some dataset $D$ of sequences, we can estimate an n-gram model through counting, derived as follows:\n",
        "\n",
        "\\begin{align}\n",
        "p(w_t|w_{t-n+1},\\ldots,w_{t-1}) &= \\frac{p(w_{t-n+1},\\ldots,w_t)}{p(w_{t-n+1},\\ldots,w_{t-1})} & \\text{definition of conditional probability}\\\\\n",
        "                       &= \\frac{p(w_{t-n+1},\\ldots,w_t)}{\\sum_{w_{t'}}p(w_{t-n+1},\\ldots,w_{t-1},w_{t'})}\\\\\n",
        "                       &\\approx \\frac{\\frac{1}{N}\\text{count}(w_{t-n+1},\\ldots,w_t)}{\\frac{1}{N}\\sum_{w_{t'}}\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})}\\\\\n",
        "                       &= \\frac{\\text{count}(w_{t-n+1},\\ldots,w_t)}{\\sum_{w_{t'}}\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})}\\\\\n",
        "                       &= \\frac{\\text{count}(w_{t-n+1},\\ldots,w_t)}{\\text{count}(w_{t-n+1},\\ldots,w_{t-1})},\n",
        "\\end{align}\n",
        "\n",
        "where $N$ is the number of $n$-grams in the dataset.\n",
        "\n",
        "In Python, we can collect these counts into a dictionary mapping a prefix to a dictionary of counts:\n",
        "\n",
        "        count[(w_n+1,...,w_t-1)] = {wt1: count of (w_n+1,...,w_t1),\n",
        "                                    wt2: count of (w_n+1,...,w_t2),\n",
        "                                    ...\n",
        "                                   }\n",
        "                                   \n",
        "and for the denominator, maintain a dictionary of totals:\n",
        "\n",
        "        total[(w_n+1,...,w_t-1)] = count of w_n+1,...,w_t-1\n",
        "\n",
        "Now that we've discussed some preliminaries, let's get started importing some basic packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzfgqhLboixd",
        "outputId": "dfb529ce-a80f-4bec-8141-e4a9eb462a70"
      },
      "source": [
        "%pylab inline\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KwAU7tqoixh"
      },
      "source": [
        "### Simplified Language\n",
        "\n",
        "To get intuition, lets start by modeling a simple language called `ABC`. A word in this language is one of three tokens, $$w\\in \\{\\texttt{A, B, C}\\},$$\n",
        "and we'll denote a sentence as $\\textbf{w}=(w_1,\\ldots,w_{|\\textbf{w}|})$.\n",
        "\n",
        "\n",
        "Suppose we are given the following dataset, and want to estimate a **bigram model**: $$p(\\textbf{w})\\approx\\prod_{t=1}^{|\\textbf{w}|}p(w_t|w_{t-1})\\quad\\quad(*)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPQ2ojw_oixh"
      },
      "source": [
        "data_raw = [['A', 'A', 'B', 'B'],\n",
        "            ['A', 'A', 'B'],\n",
        "            ['A', 'A', 'B', 'C'],\n",
        "            ['A', 'A', 'A'],\n",
        "            ['A', 'A', 'A', 'A']]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z02adyL1oixh"
      },
      "source": [
        "Since our model is a probability distribution, the total probability of all possible strings in the language must sum to 1, i.e.: $$\\sum_{\\textbf{w}}p(\\textbf{w})=1.$$\n",
        "\n",
        "In order to satisfy this criterion it turns out that we need an additional **beginning token**, `<bos>`, and **end token**, `<eos>`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0DcPYiqoixi",
        "outputId": "8e6048c2-29fe-405f-84a0-0b1420488b90"
      },
      "source": [
        "data = [['<bos>'] + d + ['<eos>'] for d in data_raw]\n",
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<bos>', 'A', 'A', 'B', 'B', '<eos>'],\n",
              " ['<bos>', 'A', 'A', 'B', '<eos>'],\n",
              " ['<bos>', 'A', 'A', 'B', 'C', '<eos>'],\n",
              " ['<bos>', 'A', 'A', 'A', '<eos>'],\n",
              " ['<bos>', 'A', 'A', 'A', 'A', '<eos>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwRS9Hjcoixi"
      },
      "source": [
        "Now let's estimate a bigram model:\n",
        "\n",
        "\\begin{align}\n",
        "p(w_t|w_{t-1}) &= \\frac{\\text{count}(w_{t-1}w_{t})}{\\sum_{w_{t'}}\\text{count}(w_{t-1}w_{t'})}\\\\\n",
        "               &= \\texttt{count[prefix][wt] / totals[prefix]}\n",
        "\\end{align} \n",
        "\n",
        "where $\\texttt{prefix}$ is $w_{t-1}$ in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvTTOJUsoixi"
      },
      "source": [
        "count = defaultdict(lambda: defaultdict(float))\n",
        "total = defaultdict(float)\n",
        "\n",
        "n = 2\n",
        "for sequence in data:\n",
        "    for i in range(len(sequence)-n+1):         # for each ngram\n",
        "        ngram = tuple(sequence[i:i+n])\n",
        "        prefix, word = ngram[:-1], ngram[-1]\n",
        "        count[prefix][word] += 1               # count(w_{t-n+1}...w_t)\n",
        "        total[prefix] += 1                     # count(w_{t-n+1}...w_{t-1})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGt2Zw6qoixj"
      },
      "source": [
        "Let's see if the counts and totals make sense:\n",
        "\n",
        "- How many times did (A, B) occur? What about (B, B)?\n",
        "- How many times did (A) occur? What about (C)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQhagJXqoixj",
        "outputId": "7f638485-1a34-4bc8-8fea-17870b1e4dce"
      },
      "source": [
        "print(\"Counts:\")\n",
        "dict(count)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counts:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('<bos>',): defaultdict(float, {'A': 5.0}),\n",
              " ('A',): defaultdict(float, {'<eos>': 2.0, 'A': 8.0, 'B': 3.0}),\n",
              " ('B',): defaultdict(float, {'<eos>': 2.0, 'B': 1.0, 'C': 1.0}),\n",
              " ('C',): defaultdict(float, {'<eos>': 1.0})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7JCdKQDtbcJ",
        "outputId": "7ce01579-8066-4a2a-f990-ea88bbe9f836"
      },
      "source": [
        "print(\"\\nTotals:\")\n",
        "dict(total)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Totals:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('<bos>',): 5.0, ('A',): 13.0, ('B',): 4.0, ('C',): 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtlEY2r_oixj"
      },
      "source": [
        "#### Conditional probability queries\n",
        "\n",
        "We can now query a conditional probability:\n",
        "\n",
        "\\begin{align}\n",
        "\\texttt{p(word|prefix)} =&\\ \\texttt{count[prefix][word] / totals[prefix]}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx9DGJC1oixj",
        "outputId": "f51a2573-fba5-485e-f2e1-819791ad0f73"
      },
      "source": [
        "queries = [('<bos>', 'A'),\n",
        "           ('B', 'C')]\n",
        "\n",
        "for query in queries:\n",
        "    prefix, word = query[:-1], query[-1]\n",
        "    p = count[prefix][word] / total[prefix]  # We'll discuss the case when `total[prefix] = 0` below.\n",
        "    print(\"p( %s | %s) = \\t%.5f\" % (word, ', '.join(prefix), p))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p( A | <bos>) = \t1.00000\n",
            "p( C | B) = \t0.25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omql0E5doixk"
      },
      "source": [
        "**Exercise**: Look at the training set and convince yourself that these conditional probabilities are correct according to the count-based estimation procedure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFu4RFSYoixk"
      },
      "source": [
        "#### Sequence Probability\n",
        "\n",
        "We can compute the probability of a sequence using the conditional probabilities along with the chain rule of probability:\n",
        "\n",
        "\\begin{align}\n",
        "p(w_1,\\ldots,w_T)&\\approx\\prod_{t=1}^T p(w_t|w_{t-1})\n",
        "\\end{align}\n",
        "\n",
        "(Here $w_0$ is `<bos>` and $w_T$ is `<eos>`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZk5zfwCoixk",
        "outputId": "31464f31-c733-48e6-9554-a08136daef2b"
      },
      "source": [
        "sequence = ['<bos>', 'A', 'A', 'B', '<eos>']\n",
        "\n",
        "def sequence_p(sequence, log=False):\n",
        "    total_p = 1\n",
        "\n",
        "    for i in range(len(sequence)-n+1):\n",
        "        ngram = tuple(sequence[i:i+n])\n",
        "        prefix = ngram[:-1]\n",
        "        word = ngram[-1]\n",
        "        p = count[prefix][word] / max(total[prefix], 1)\n",
        "        if log:\n",
        "            print(\"p(%s | %s) =\\t%.3f\" % (word, ', '.join(prefix), p))\n",
        "\n",
        "        total_p *= p\n",
        "    return total_p\n",
        "    \n",
        "\n",
        "print(\"\\nProduct: p(%s) = %.3f\" % (''.join(sequence[1:-1]), sequence_p(sequence, log=True)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p(A | <bos>) =\t1.000\n",
            "p(A | A) =\t0.615\n",
            "p(B | A) =\t0.231\n",
            "p(<eos> | B) =\t0.500\n",
            "\n",
            "Product: p(AAB) = 0.071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT-a0sRRoixl"
      },
      "source": [
        "### Real Example: Dialogue Utterances\n",
        "\n",
        "Now lets use the same ideas on a more realistic text corpus.\n",
        "\n",
        "We will use utterances from a dialogue dataset called **Persona-Chat**. This dataset is relatively small and centers on a single domain, but it is simple and interpretable for our purposes here. You can download it as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJO9LlECw7Wn",
        "outputId": "4bcfbbf3-c427-43da-97d3-0ad861969f4b"
      },
      "source": [
        "if not os.path.exists('personachat_all_sentences_train.jsonl'):\n",
        "    !wget \"https://nyu.box.com/shared/static/q4nvswb0szelivhgyx87vd1056ttqfyi.jsonl\" -O 'personachat_all_sentences_train.jsonl'\n",
        "if not os.path.exists('personachat_all_sentences_valid.jsonl'):\n",
        "    !wget \"https://nyu.box.com/shared/static/8krcizo8sms1m0ppy7uiwfcx4a3l5nsq.jsonl\" -O 'personachat_all_sentences_valid.jsonl'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-16 21:45:51--  https://nyu.box.com/shared/static/q4nvswb0szelivhgyx87vd1056ttqfyi.jsonl\n",
            "Resolving nyu.box.com (nyu.box.com)... 107.152.26.197\n",
            "Connecting to nyu.box.com (nyu.box.com)|107.152.26.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/q4nvswb0szelivhgyx87vd1056ttqfyi.jsonl [following]\n",
            "--2021-05-16 21:45:51--  https://nyu.box.com/public/static/q4nvswb0szelivhgyx87vd1056ttqfyi.jsonl\n",
            "Reusing existing connection to nyu.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://nyu.app.box.com/public/static/q4nvswb0szelivhgyx87vd1056ttqfyi.jsonl [following]\n",
            "--2021-05-16 21:45:52--  https://nyu.app.box.com/public/static/q4nvswb0szelivhgyx87vd1056ttqfyi.jsonl\n",
            "Resolving nyu.app.box.com (nyu.app.box.com)... 107.152.26.201\n",
            "Connecting to nyu.app.box.com (nyu.app.box.com)|107.152.26.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!ql_VJd6HJN5jMxF4SLkh8f7oltSoLeDOU433TSod9uUzFpEsU82jWTjXKpGYd6bufC3GnMYsWdoSMcgiQEu_zFPqTemMeRGkDqIG8xMnwcQwJpI4aKTHjqiGOF2jCvg7tfnhHYxmCmzQGoWj3WrhXKKfg1zhint7C4Kqu4qyXMMVGkuYoyw2diUtFjf6Z1N49YF2U4lZsQd20oM6yIfzDTg6Nxmk5Nbpt52JZRdi2clNWw9XPeXmdsYfJlIzCtTmy55r3Y3_hpftuaC8XL9L0SpEJuv0UURUGx2kv-Nn2UHlizOwaH6JPLHtDZRHNMvmeX3eNLaGVX-IKxhsQ6Z4al6S9Oat8SHcLS8zqEWy0pKirqfmSbTQLBiR5Aj5PD5wWWF1nmbUeYaKhYmrhJmQvYKm_n-GSusdv1ODzzqVJqguqI3YB42EP-wEQRLaYUjb8t53LFPVGiKXCzMuUjRJxzsF2dVuOnHn-cIFMELbQUd4yVeCoflfKEwXKFI09aukS7FH9CCb9GdZa9MDjY7AEGoYtwSPHl5GL8a7_yfUKgHVysBmuGgF7Q_LYuFO8zg-lHhz3JWX3Y8Jqi3R2XhokzMKBO5JktYk4Ts9DKpnix77ItryU4XX7JL1nRXITYD4h3iuQ-Hy36YGLJUHU_svMR79Aw1Hd0cp7yKv6UEk65N5DMQkbYUe90J38Y4RIOYKqTLj82ZmafXIVGFLHUf2zvBJ7dHkglef0kKYmvEA-bahYuxjAqee6wcODTjcbi4zpHbOzV1V1p84GIjcZXr5Ov3q3pxJ1X_9iy_9XXtzOEmqx7HYniBCfO2FyPxMKEwX54LTQfNYzTxVqXho3cRs3pOeny9WnXAsfqg0eXAIvE5TW3mwJoFDriyFuIJ5hr6Jgx7yXx3z69g8-y_LMLxwFZOSJqWRiJaQBCAs-7WskYh_y4R0sf4aOFpsnJtR4CLLqNC113yddWGQ2DUGIDpj-T7AhUJXEv2VIhW7bQAQCT_dq7-Z1Ip5QNfZ3hHpHdieJgaEIiwKoXm5FWDzTLcAw3I6AGY46KkBfVayNicRnoawn-2KDRYWkLa4gN-cgOXAqZx0TzW9qu5mVFSJyAgyEyxay31grnNqJCrHaa7vbMVb_8VmgdUpbArLkllXUcVSQNPxaV6Tj9PGABTCvUbWMnBv450yZSgi6VuqeTsSl72UULaVXbGoSAw0wX27n-vPFNNveGJ9fgSZxuUi4UxeXHBmH_BmDGNdK3kCPr-TWUtl9_rkswVO--qSi8S3HwlDJjdA7YX8aEQ5oIcRa9vysnxnoInPILQhsXE6yHjTiKUmLNy_uKNo1KcCeq-_PVRcPMvPLvGnqucznC6vlcPBBYsdi1mC91KSIlhrJCqbz7LDg1CQh0baPsw7X3MfLo5HIERRyQdanwCn_3GT38SuHyQYGCDXBuNB4ZrH1FcDpmvFI3RHCQYhT6t-WWSGe0M96Tt9Dg../download [following]\n",
            "--2021-05-16 21:45:52--  https://public.boxcloud.com/d/1/b1!ql_VJd6HJN5jMxF4SLkh8f7oltSoLeDOU433TSod9uUzFpEsU82jWTjXKpGYd6bufC3GnMYsWdoSMcgiQEu_zFPqTemMeRGkDqIG8xMnwcQwJpI4aKTHjqiGOF2jCvg7tfnhHYxmCmzQGoWj3WrhXKKfg1zhint7C4Kqu4qyXMMVGkuYoyw2diUtFjf6Z1N49YF2U4lZsQd20oM6yIfzDTg6Nxmk5Nbpt52JZRdi2clNWw9XPeXmdsYfJlIzCtTmy55r3Y3_hpftuaC8XL9L0SpEJuv0UURUGx2kv-Nn2UHlizOwaH6JPLHtDZRHNMvmeX3eNLaGVX-IKxhsQ6Z4al6S9Oat8SHcLS8zqEWy0pKirqfmSbTQLBiR5Aj5PD5wWWF1nmbUeYaKhYmrhJmQvYKm_n-GSusdv1ODzzqVJqguqI3YB42EP-wEQRLaYUjb8t53LFPVGiKXCzMuUjRJxzsF2dVuOnHn-cIFMELbQUd4yVeCoflfKEwXKFI09aukS7FH9CCb9GdZa9MDjY7AEGoYtwSPHl5GL8a7_yfUKgHVysBmuGgF7Q_LYuFO8zg-lHhz3JWX3Y8Jqi3R2XhokzMKBO5JktYk4Ts9DKpnix77ItryU4XX7JL1nRXITYD4h3iuQ-Hy36YGLJUHU_svMR79Aw1Hd0cp7yKv6UEk65N5DMQkbYUe90J38Y4RIOYKqTLj82ZmafXIVGFLHUf2zvBJ7dHkglef0kKYmvEA-bahYuxjAqee6wcODTjcbi4zpHbOzV1V1p84GIjcZXr5Ov3q3pxJ1X_9iy_9XXtzOEmqx7HYniBCfO2FyPxMKEwX54LTQfNYzTxVqXho3cRs3pOeny9WnXAsfqg0eXAIvE5TW3mwJoFDriyFuIJ5hr6Jgx7yXx3z69g8-y_LMLxwFZOSJqWRiJaQBCAs-7WskYh_y4R0sf4aOFpsnJtR4CLLqNC113yddWGQ2DUGIDpj-T7AhUJXEv2VIhW7bQAQCT_dq7-Z1Ip5QNfZ3hHpHdieJgaEIiwKoXm5FWDzTLcAw3I6AGY46KkBfVayNicRnoawn-2KDRYWkLa4gN-cgOXAqZx0TzW9qu5mVFSJyAgyEyxay31grnNqJCrHaa7vbMVb_8VmgdUpbArLkllXUcVSQNPxaV6Tj9PGABTCvUbWMnBv450yZSgi6VuqeTsSl72UULaVXbGoSAw0wX27n-vPFNNveGJ9fgSZxuUi4UxeXHBmH_BmDGNdK3kCPr-TWUtl9_rkswVO--qSi8S3HwlDJjdA7YX8aEQ5oIcRa9vysnxnoInPILQhsXE6yHjTiKUmLNy_uKNo1KcCeq-_PVRcPMvPLvGnqucznC6vlcPBBYsdi1mC91KSIlhrJCqbz7LDg1CQh0baPsw7X3MfLo5HIERRyQdanwCn_3GT38SuHyQYGCDXBuNB4ZrH1FcDpmvFI3RHCQYhT6t-WWSGe0M96Tt9Dg../download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.26.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.26.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13403897 (13M) [application/octet-stream]\n",
            "Saving to: ‘personachat_all_sentences_train.jsonl’\n",
            "\n",
            "personachat_all_sen 100%[===================>]  12.78M  14.9MB/s    in 0.9s    \n",
            "\n",
            "2021-05-16 21:45:54 (14.9 MB/s) - ‘personachat_all_sentences_train.jsonl’ saved [13403897/13403897]\n",
            "\n",
            "--2021-05-16 21:45:54--  https://nyu.box.com/shared/static/8krcizo8sms1m0ppy7uiwfcx4a3l5nsq.jsonl\n",
            "Resolving nyu.box.com (nyu.box.com)... 107.152.26.197\n",
            "Connecting to nyu.box.com (nyu.box.com)|107.152.26.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/8krcizo8sms1m0ppy7uiwfcx4a3l5nsq.jsonl [following]\n",
            "--2021-05-16 21:45:55--  https://nyu.box.com/public/static/8krcizo8sms1m0ppy7uiwfcx4a3l5nsq.jsonl\n",
            "Reusing existing connection to nyu.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://nyu.app.box.com/public/static/8krcizo8sms1m0ppy7uiwfcx4a3l5nsq.jsonl [following]\n",
            "--2021-05-16 21:45:55--  https://nyu.app.box.com/public/static/8krcizo8sms1m0ppy7uiwfcx4a3l5nsq.jsonl\n",
            "Resolving nyu.app.box.com (nyu.app.box.com)... 107.152.26.201\n",
            "Connecting to nyu.app.box.com (nyu.app.box.com)|107.152.26.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!XvO_V0dSDrLlIPTElNbv1wdkqHr3uOd_cjhKymeL6Zkyu1m6Nd5Ttu0jaJGjCrHFNx6OY1p5reviRXJuLvwHs4PVX0rfy6Ijhnv59qh14wRXRD_ZSdXcDzhYbq_6Vg0sCZGMVTQRmHpF6pbeXKWYW4PdPW8Y1FH2brY_NY1VS-dt1WHghAIBB2vt7k5P0IL2VKCN8rHf5KeTw-JF_2f9tnHF30kFgqLtNw_VrI0Li_LNhFebYG7wf7-wXrCrvM4wsZAh6x3mHO9bn4cz0FsY6zI6cdcgJJyMq0HZ_2XIRfF0oABSUnANiOrg4gbswU1fZCbk0Zs63MspwUeiUxJMVd6Qk-IlZt_T4KkTTWOuwCBkddSpoO6ceWmU7TK9e9Ff68lq35AhgOC7_0FBmaRrrCIhGnRza4h2vHoTrY3YvHbwtfgqRBwLq9-yqteiJeARenJwVK4dT4n4qpj7FCLSXj1CFcZLCAijnxiltt4g4PpRPt0nt-WUkK4Aidhu7ohXHq6qD7I4LCI-MpbKKr7USg81PqgLx0Uk2Y2bICNFZdxeNvcFDk9BGOpSZtxfy7kFZ0_NTIEOZKvkCerMPp_G5BexwUNWPxmv-HjYzHFQu3MGEcIXyHEDRTdmJVZW5ruis2z0iNuTDUX2q4ixrjcoFLbkgdQuZkK-Hp5mun35SSiillIWdLt6GKwHv87dewbjthQ_yU-B2PN8itn8_-TmoONA_A7lRuWI27JiI71k2_q94QJy1AfntuTC9xtLB38HB9mB3GPIJn0Xd-VC6QJmviMjCn2HOQZdL2foFJRKE5gDJbGBK3FKXPvc2UYWHcpbqGN-lydVEKP_lbUGLnXU5SFwJ05T7uaS4mKISbMP3HygNERkb2K-FY5PtZikMZD1LpCwY0PyAw1iqDgx2YFOpxFXHqGw5bwcgNWDECH3KtSjqpO2hs644ocuV9kCEG0G4rXry_i-Hc_w1TkVO47MvY3e1bDkAxd_Z_F2bHFjg5B-uk57X2z2PMarGk_U-lxBwkJKu0Wf2fcb0tTlaJ0ot93y63dQ6T0_CP9pbLILyOcnrpigHm5uTYyFwAq5rst4Vl5dNvwU_x0qLqHFQYuLUVnsE3dgFFqVi7irm3UcCM96qUg9tU5HB4F15z7T7HQSrdQwhaPmxFD9jJ2T0xA9T05eNwo9Un20QXNNDnIJukMliXiFLEIfpuowkVXH61i3FsePUiJbS-g0kuQx7Mz93JKXfcBZrMeNMAk7PldpeRezxN42NxKLThU7T7eXK1pflu0q7wi8qH3um9AaVfho0oqLVWzPKdWFL0JEHlShFSPQnjXZ2cv-2y91yg8pzRVtXmtvfpYczqYIpx5ydGVBqQ4ZlZLn4W46nQmMXOonaUW0UTO0zqwfhrB_oETwDolDRQVgpjehi-c2Xs8E7Y_XzsI9moglBXFMoA../download [following]\n",
            "--2021-05-16 21:45:56--  https://public.boxcloud.com/d/1/b1!XvO_V0dSDrLlIPTElNbv1wdkqHr3uOd_cjhKymeL6Zkyu1m6Nd5Ttu0jaJGjCrHFNx6OY1p5reviRXJuLvwHs4PVX0rfy6Ijhnv59qh14wRXRD_ZSdXcDzhYbq_6Vg0sCZGMVTQRmHpF6pbeXKWYW4PdPW8Y1FH2brY_NY1VS-dt1WHghAIBB2vt7k5P0IL2VKCN8rHf5KeTw-JF_2f9tnHF30kFgqLtNw_VrI0Li_LNhFebYG7wf7-wXrCrvM4wsZAh6x3mHO9bn4cz0FsY6zI6cdcgJJyMq0HZ_2XIRfF0oABSUnANiOrg4gbswU1fZCbk0Zs63MspwUeiUxJMVd6Qk-IlZt_T4KkTTWOuwCBkddSpoO6ceWmU7TK9e9Ff68lq35AhgOC7_0FBmaRrrCIhGnRza4h2vHoTrY3YvHbwtfgqRBwLq9-yqteiJeARenJwVK4dT4n4qpj7FCLSXj1CFcZLCAijnxiltt4g4PpRPt0nt-WUkK4Aidhu7ohXHq6qD7I4LCI-MpbKKr7USg81PqgLx0Uk2Y2bICNFZdxeNvcFDk9BGOpSZtxfy7kFZ0_NTIEOZKvkCerMPp_G5BexwUNWPxmv-HjYzHFQu3MGEcIXyHEDRTdmJVZW5ruis2z0iNuTDUX2q4ixrjcoFLbkgdQuZkK-Hp5mun35SSiillIWdLt6GKwHv87dewbjthQ_yU-B2PN8itn8_-TmoONA_A7lRuWI27JiI71k2_q94QJy1AfntuTC9xtLB38HB9mB3GPIJn0Xd-VC6QJmviMjCn2HOQZdL2foFJRKE5gDJbGBK3FKXPvc2UYWHcpbqGN-lydVEKP_lbUGLnXU5SFwJ05T7uaS4mKISbMP3HygNERkb2K-FY5PtZikMZD1LpCwY0PyAw1iqDgx2YFOpxFXHqGw5bwcgNWDECH3KtSjqpO2hs644ocuV9kCEG0G4rXry_i-Hc_w1TkVO47MvY3e1bDkAxd_Z_F2bHFjg5B-uk57X2z2PMarGk_U-lxBwkJKu0Wf2fcb0tTlaJ0ot93y63dQ6T0_CP9pbLILyOcnrpigHm5uTYyFwAq5rst4Vl5dNvwU_x0qLqHFQYuLUVnsE3dgFFqVi7irm3UcCM96qUg9tU5HB4F15z7T7HQSrdQwhaPmxFD9jJ2T0xA9T05eNwo9Un20QXNNDnIJukMliXiFLEIfpuowkVXH61i3FsePUiJbS-g0kuQx7Mz93JKXfcBZrMeNMAk7PldpeRezxN42NxKLThU7T7eXK1pflu0q7wi8qH3um9AaVfho0oqLVWzPKdWFL0JEHlShFSPQnjXZ2cv-2y91yg8pzRVtXmtvfpYczqYIpx5ydGVBqQ4ZlZLn4W46nQmMXOonaUW0UTO0zqwfhrB_oETwDolDRQVgpjehi-c2Xs8E7Y_XzsI9moglBXFMoA../download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.26.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.26.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1640194 (1.6M) [application/octet-stream]\n",
            "Saving to: ‘personachat_all_sentences_valid.jsonl’\n",
            "\n",
            "personachat_all_sen 100%[===================>]   1.56M  3.05MB/s    in 0.5s    \n",
            "\n",
            "2021-05-16 21:45:57 (3.05 MB/s) - ‘personachat_all_sentences_valid.jsonl’ saved [1640194/1640194]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeHhd6-goixl"
      },
      "source": [
        "#### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cugmahcCoixl",
        "outputId": "91e78ae1-5abd-4190-aa5f-3ff6f97616a8"
      },
      "source": [
        "train = []\n",
        "valid = []\n",
        "\n",
        "for ds, name in [(train, 'train'), (valid, 'valid')]:\n",
        "    with open('personachat_all_sentences_%s.jsonl' % name, 'r') as f:\n",
        "        for line in f:\n",
        "            ds.append(json.loads(line)['tokens'])\n",
        "        \n",
        "vocab = list(set([t for ts in train for t in ts]))      \n",
        "print(\"Number of train examples: %d\" % (len(train)))\n",
        "print(\"Number of valid examples: %d\" % (len(valid)))\n",
        "print(\"Vocab size: %d\" % (len(vocab)))\n",
        "\n",
        "print(\"\\nExamples:\")\n",
        "train[:3]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train examples: 133176\n",
            "Number of valid examples: 16181\n",
            "Vocab size: 19153\n",
            "\n",
            "Examples:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i', 'am', 'doing', 'great', 'except', 'for', 'the', 'allergies', '.'],\n",
              " ['i', 'am', 'a', 'woman', 'what', 'about', 'you', '.'],\n",
              " ['i', 'thought', 'you', 'were', 'a', 'college', 'kid', '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyS4KXRroixm"
      },
      "source": [
        "#### Convert tokenized data to input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8188ad2139a046339eec575e3758cde0",
            "ae3357a3d4014104ab6fa5924ddba0b6",
            "7591c1e23a5b4a2aaf4b990483a4df0d",
            "7c7caeea1f71413f9366b29764a8c2fb",
            "a4a2711ba7684b0e98add041c2034f35",
            "e883a942c39243b3b3c351e7ecf0c29a",
            "99e06b0d12904edd8b89a5f3f3d39def",
            "4982c7056add4b87a364b32a5da703e2"
          ]
        },
        "id": "iQeIgDBboixm",
        "outputId": "3b663c08-47ab-4298-e3b2-5632078d7434"
      },
      "source": [
        "os.makedirs('data/tokenized', exist_ok=True)\n",
        "with open('data/tokenized/pchat_train', 'w') as f:\n",
        "    for line in tqdm(train):\n",
        "        f.write(' '.join(line))\n",
        "        f.write('\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8188ad2139a046339eec575e3758cde0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=133176.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrdYu_6Soixm"
      },
      "source": [
        "### KenLM\n",
        "\n",
        "We'll use an off-the-shelf ngram modeling package called `KenLM`. KenLM estimates n-gram language models using **modified Kneser-Ney smoothing**, and has a fast and memory-efficient implementation. \n",
        "- While we won't go into details here, **smoothing** is a technique used to account for ngrams that do not occur in the training corpus. \n",
        "- Normally, these ngrams would receive zero-probability mass. Smoothing ensures every ngram receives some probability.\n",
        "\n",
        "\n",
        "\n",
        "Please see page 48 of the [lecture note](https://github.com/nyu-dl/NLP_DL_Lecture_Note/blob/master/lecture_note.pdf) for an overview of Kneser-Ney smoothing, and [[Chen & Goodman 1998]](https://dash.harvard.edu/bitstream/handle/1/25104739/tr-10-98.pdf?sequence=1) for further details.\n",
        "\n",
        "Let's install KenLM below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyrqXUyepFzZ",
        "outputId": "aa85be72-44be-4f04-820f-60081ac44783"
      },
      "source": [
        "!wget -O - https://kheafield.com/code/kenlm.tar.gz |tar xz\n",
        "!mkdir /content/kenlm/build; cd /content/kenlm/build; cmake ..; make -j 4\n",
        "!cd /content/kenlm; python setup.py install\n",
        "KENLM_DIR='/content/kenlm'\n",
        "\n",
        "!pip install pypi-kenlm"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-16 21:45:58--  https://kheafield.com/code/kenlm.tar.gz\n",
            "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491090 (480K) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 479.58K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-05-16 21:45:58 (16.6 MB/s) - written to stdout [491090/491090]\n",
            "\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Looking for pthread_create\n",
            "-- Looking for pthread_create - not found\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   program_options\n",
            "--   system\n",
            "--   thread\n",
            "--   unit_test_framework\n",
            "--   chrono\n",
            "--   date_time\n",
            "--   atomic\n",
            "-- Check if compiler accepts -pthread\n",
            "-- Check if compiler accepts -pthread - yes\n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.6\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/include (found version \"5.2.2\") \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/kenlm/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_util\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "\u001b[35m\u001b[1mScanning dependencies of target probing_hash_table_benchmark\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_filter\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 52%] Built target kenlm_filter\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 61%] Built target probing_hash_table_benchmark\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fragment\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target build_binary\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_benchmark\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target query\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 77%] Built target fragment\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_builder\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 80%] Built target build_binary\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 82%] Built target query\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target phrase_table_vocab\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target filter\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 91%] Built target phrase_table_vocab\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 92%] Built target kenlm_benchmark\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 93%] Built target kenlm_builder\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lmplz\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target count_ngrams\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 97%] Built target lmplz\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 98%] Built target filter\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating kenlm.egg-info\n",
            "writing kenlm.egg-info/PKG-INFO\n",
            "writing dependency_links to kenlm.egg-info/dependency_links.txt\n",
            "writing top-level names to kenlm.egg-info/top_level.txt\n",
            "writing manifest file 'kenlm.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
            "adding license file 'COPYING.3' (matched pattern 'COPYING*')\n",
            "adding license file 'COPYING' (matched pattern 'COPYING*')\n",
            "adding license file 'COPYING.LESSER.3' (matched pattern 'COPYING*')\n",
            "reading manifest file 'kenlm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'kenlm.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'kenlm' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/util\n",
            "creating build/temp.linux-x86_64-3.7/lm\n",
            "creating build/temp.linux-x86_64-3.7/util/double-conversion\n",
            "creating build/temp.linux-x86_64-3.7/python\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/mmap.cc -o build/temp.linux-x86_64-3.7/util/mmap.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/file.cc -o build/temp.linux-x86_64-3.7/util/file.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/pool.cc -o build/temp.linux-x86_64-3.7/util/pool.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/murmur_hash.cc -o build/temp.linux-x86_64-3.7/util/murmur_hash.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/usage.cc -o build/temp.linux-x86_64-3.7/util/usage.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/integer_to_string.cc -o build/temp.linux-x86_64-3.7/util/integer_to_string.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/exception.cc -o build/temp.linux-x86_64-3.7/util/exception.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/bit_packing.cc -o build/temp.linux-x86_64-3.7/util/bit_packing.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/float_to_string.cc -o build/temp.linux-x86_64-3.7/util/float_to_string.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/read_compressed.cc -o build/temp.linux-x86_64-3.7/util/read_compressed.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/ersatz_progress.cc -o build/temp.linux-x86_64-3.7/util/ersatz_progress.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/scoped.cc -o build/temp.linux-x86_64-3.7/util/scoped.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/string_piece.cc -o build/temp.linux-x86_64-3.7/util/string_piece.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/file_piece.cc -o build/temp.linux-x86_64-3.7/util/file_piece.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/parallel_read.cc -o build/temp.linux-x86_64-3.7/util/parallel_read.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/spaces.cc -o build/temp.linux-x86_64-3.7/util/spaces.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/model.cc -o build/temp.linux-x86_64-3.7/lm/model.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/binary_format.cc -o build/temp.linux-x86_64-3.7/lm/binary_format.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/vocab.cc -o build/temp.linux-x86_64-3.7/lm/vocab.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/value_build.cc -o build/temp.linux-x86_64-3.7/lm/value_build.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/virtual_interface.cc -o build/temp.linux-x86_64-3.7/lm/virtual_interface.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/quantize.cc -o build/temp.linux-x86_64-3.7/lm/quantize.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/sizes.cc -o build/temp.linux-x86_64-3.7/lm/sizes.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/lm_exception.cc -o build/temp.linux-x86_64-3.7/lm/lm_exception.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/search_hashed.cc -o build/temp.linux-x86_64-3.7/lm/search_hashed.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/search_trie.cc -o build/temp.linux-x86_64-3.7/lm/search_trie.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/read_arpa.cc -o build/temp.linux-x86_64-3.7/lm/read_arpa.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/bhiksha.cc -o build/temp.linux-x86_64-3.7/lm/bhiksha.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/config.cc -o build/temp.linux-x86_64-3.7/lm/config.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/trie_sort.cc -o build/temp.linux-x86_64-3.7/lm/trie_sort.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c lm/trie.cc -o build/temp.linux-x86_64-3.7/lm/trie.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/double-conversion/double-conversion.cc -o build/temp.linux-x86_64-3.7/util/double-conversion/double-conversion.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/double-conversion/cached-powers.cc -o build/temp.linux-x86_64-3.7/util/double-conversion/cached-powers.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/double-conversion/fixed-dtoa.cc -o build/temp.linux-x86_64-3.7/util/double-conversion/fixed-dtoa.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/double-conversion/fast-dtoa.cc -o build/temp.linux-x86_64-3.7/util/double-conversion/fast-dtoa.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/double-conversion/bignum-dtoa.cc -o build/temp.linux-x86_64-3.7/util/double-conversion/bignum-dtoa.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/double-conversion/bignum.cc -o build/temp.linux-x86_64-3.7/util/double-conversion/bignum.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/double-conversion/strtod.cc -o build/temp.linux-x86_64-3.7/util/double-conversion/strtod.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c util/double-conversion/diy-fp.cc -o build/temp.linux-x86_64-3.7/util/double-conversion/diy-fp.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c python/score_sentence.cc -o build/temp.linux-x86_64-3.7/python/score_sentence.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/include/python3.7m -c python/kenlm.cpp -o build/temp.linux-x86_64-3.7/python/kenlm.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/util/mmap.o build/temp.linux-x86_64-3.7/util/file.o build/temp.linux-x86_64-3.7/util/pool.o build/temp.linux-x86_64-3.7/util/murmur_hash.o build/temp.linux-x86_64-3.7/util/usage.o build/temp.linux-x86_64-3.7/util/integer_to_string.o build/temp.linux-x86_64-3.7/util/exception.o build/temp.linux-x86_64-3.7/util/bit_packing.o build/temp.linux-x86_64-3.7/util/float_to_string.o build/temp.linux-x86_64-3.7/util/read_compressed.o build/temp.linux-x86_64-3.7/util/ersatz_progress.o build/temp.linux-x86_64-3.7/util/scoped.o build/temp.linux-x86_64-3.7/util/string_piece.o build/temp.linux-x86_64-3.7/util/file_piece.o build/temp.linux-x86_64-3.7/util/parallel_read.o build/temp.linux-x86_64-3.7/util/spaces.o build/temp.linux-x86_64-3.7/lm/model.o build/temp.linux-x86_64-3.7/lm/binary_format.o build/temp.linux-x86_64-3.7/lm/vocab.o build/temp.linux-x86_64-3.7/lm/value_build.o build/temp.linux-x86_64-3.7/lm/virtual_interface.o build/temp.linux-x86_64-3.7/lm/quantize.o build/temp.linux-x86_64-3.7/lm/sizes.o build/temp.linux-x86_64-3.7/lm/lm_exception.o build/temp.linux-x86_64-3.7/lm/search_hashed.o build/temp.linux-x86_64-3.7/lm/search_trie.o build/temp.linux-x86_64-3.7/lm/read_arpa.o build/temp.linux-x86_64-3.7/lm/bhiksha.o build/temp.linux-x86_64-3.7/lm/config.o build/temp.linux-x86_64-3.7/lm/trie_sort.o build/temp.linux-x86_64-3.7/lm/trie.o build/temp.linux-x86_64-3.7/util/double-conversion/double-conversion.o build/temp.linux-x86_64-3.7/util/double-conversion/cached-powers.o build/temp.linux-x86_64-3.7/util/double-conversion/fixed-dtoa.o build/temp.linux-x86_64-3.7/util/double-conversion/fast-dtoa.o build/temp.linux-x86_64-3.7/util/double-conversion/bignum-dtoa.o build/temp.linux-x86_64-3.7/util/double-conversion/bignum.o build/temp.linux-x86_64-3.7/util/double-conversion/strtod.o build/temp.linux-x86_64-3.7/util/double-conversion/diy-fp.o build/temp.linux-x86_64-3.7/python/score_sentence.o build/temp.linux-x86_64-3.7/python/kenlm.o -lstdc++ -lrt -lz -lbz2 -llzma -o build/lib.linux-x86_64-3.7/kenlm.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/kenlm.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for kenlm.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/kenlm.py to kenlm.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying kenlm.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying kenlm.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying kenlm.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying kenlm.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.kenlm.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/kenlm-0.0.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing kenlm-0.0.0-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/kenlm-0.0.0-py3.7-linux-x86_64.egg\n",
            "Extracting kenlm-0.0.0-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding kenlm 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/kenlm-0.0.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for kenlm==0.0.0\n",
            "Finished processing dependencies for kenlm==0.0.0\n",
            "Collecting pypi-kenlm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/cb/67310dc4524d61ed6460d7618709b40e81b82922fdbd9cb78a6e50ec6d86/pypi-kenlm-0.1.20210121.tar.gz (253kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 4.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pypi-kenlm\n",
            "  Building wheel for pypi-kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypi-kenlm: filename=pypi_kenlm-0.1.20210121-cp37-cp37m-linux_x86_64.whl size=2312294 sha256=e6403153febe7f0704c4e4149e67105f5e265dd40ed2a80c54f7c1b67feda68a\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/20/04/ddc880980d333a6f029e199a7f69535a48f1e57406d14ce518\n",
            "Successfully built pypi-kenlm\n",
            "Installing collected packages: pypi-kenlm\n",
            "Successfully installed pypi-kenlm-0.1.20210121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQBYs5x7oixm"
      },
      "source": [
        "#### Build kenlm n-gram models\n",
        "\n",
        "This uses the `kenlm` commands `lmplz` to estimate the language model, then `build_binary` to convert it to an efficient format. We load the resulting model using the `kenlm` python wrapper.\n",
        "\n",
        "We do this for n-gram models of order `2,3,4`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eej7n4nYoixn",
        "outputId": "48f6e36b-eec1-4cbb-e357-51808add7eaf"
      },
      "source": [
        "import kenlm\n",
        "\n",
        "data_prefix = 'pchat'\n",
        "dataset = 'pchat_train'\n",
        "models_dir = 'models'\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "models = {}\n",
        "for n in [2,3,4]:\n",
        "    model_temp = '%s/%s_%d.arpa' % (models_dir, data_prefix, n)\n",
        "    model_name = '%s/%s_%d.klm' % (models_dir, data_prefix, n)\n",
        "    ! cat ./data/tokenized/$dataset | $KENLM_DIR/build/bin/lmplz -o $n > $model_temp\n",
        "    ! $KENLM_DIR/build/bin/build_binary $model_temp $model_name\n",
        "    models[n] = kenlm.LanguageModel(model_name)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== 1/5 Counting and sorting n-grams ===\n",
            "File stdin isn't normal.  Using slower read() instead of mmap().  No progress bar.\n",
            "tcmalloc: large alloc 2965790720 bytes == 0x5638dfaf8000 @  0x7f58a6da71e7 0x5638dea567a2 0x5638de9f151e 0x5638de9d02eb 0x5638de9bc066 0x7f58a4f40bf7 0x5638de9bdbaa\n",
            "tcmalloc: large alloc 7908777984 bytes == 0x56399075e000 @  0x7f58a6da71e7 0x5638dea567a2 0x5638dea457ca 0x5638dea46208 0x5638de9d0308 0x5638de9bc066 0x7f58a4f40bf7 0x5638de9bdbaa\n",
            "Unigram tokens 1602042 types 19156\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:229872 2:10899497984\n",
            "tcmalloc: large alloc 10899505152 bytes == 0x563b68674000 @  0x7f58a6da71e7 0x5638dea567a2 0x5638dea457ca 0x5638dea46208 0x5638de9d08d7 0x5638de9bc066 0x7f58a4f40bf7 0x5638de9bdbaa\n",
            "Statistics:\n",
            "1 19156 D1=0.588857 D2=1.0348 D3+=1.3388\n",
            "2 231267 D1=0.708637 D2=1.06132 D3+=1.37629\n",
            "Memory estimate for binary LM:\n",
            "type      kB\n",
            "probing 4551 assuming -p 1.5\n",
            "probing 4626 assuming -r models -p 1.5\n",
            "trie    1747 without quantization\n",
            "trie    1099 assuming -q 8 -b 8 quantization \n",
            "trie    1747 assuming -a 22 array pointer compression\n",
            "trie    1099 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:229872 2:3700272\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:229872 2:3700272\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:21477264 kB\tVmRSS:2933080 kB\tRSSMax:2942796 kB\tuser:0.553272\tsys:1.47774\tCPU:2.03105\treal:2.03605\n",
            "Reading models/pchat_2.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "SUCCESS\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "File stdin isn't normal.  Using slower read() instead of mmap().  No progress bar.\n",
            "tcmalloc: large alloc 2509520896 bytes == 0x55f754d64000 @  0x7ffb75ba91e7 0x55f753b7a7a2 0x55f753b1551e 0x55f753af42eb 0x55f753ae0066 0x7ffb73d42bf7 0x55f753ae1baa\n",
            "tcmalloc: large alloc 8365056000 bytes == 0x55f7ea6a8000 @  0x7ffb75ba91e7 0x55f753b7a7a2 0x55f753b697ca 0x55f753b6a208 0x55f753af4308 0x55f753ae0066 0x7ffb73d42bf7 0x55f753ae1baa\n",
            "Unigram tokens 1602042 types 19156\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:229872 2:3791129856 3:7108368384\n",
            "tcmalloc: large alloc 7108370432 bytes == 0x55f754c62000 @  0x7ffb75ba91e7 0x55f753b7a7a2 0x55f753b697ca 0x55f753b6a208 0x55f753af48d7 0x55f753ae0066 0x7ffb73d42bf7 0x55f753ae1baa\n",
            "tcmalloc: large alloc 3791134720 bytes == 0x55f9dd8de000 @  0x7ffb75ba91e7 0x55f753b7a7a2 0x55f753b697ca 0x55f753b6a208 0x55f753af4cdd 0x55f753ae0066 0x7ffb73d42bf7 0x55f753ae1baa\n",
            "Statistics:\n",
            "1 19156 D1=0.588857 D2=1.0348 D3+=1.3388\n",
            "2 231267 D1=0.722265 D2=1.09097 D3+=1.44737\n",
            "3 617624 D1=0.798924 D2=1.0703 D3+=1.33013\n",
            "Memory estimate for binary LM:\n",
            "type       kB\n",
            "probing 16763 assuming -p 1.5\n",
            "probing 18193 assuming -r models -p 1.5\n",
            "trie     6683 without quantization\n",
            "trie     3625 assuming -q 8 -b 8 quantization \n",
            "trie     6354 assuming -a 22 array pointer compression\n",
            "trie     3296 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:229872 2:3700272 3:12352480\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:229872 2:3700272 3:12352480\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:14609272 kB\tVmRSS:2505780 kB\tRSSMax:2505828 kB\tuser:1.05081\tsys:1.16683\tCPU:2.21768\treal:2.15983\n",
            "Reading models/pchat_3.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "SUCCESS\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "File stdin isn't normal.  Using slower read() instead of mmap().  No progress bar.\n",
            "tcmalloc: large alloc 2174918656 bytes == 0x5582a6ab4000 @  0x7f9eb3eb01e7 0x5582a50fb7a2 0x5582a509651e 0x5582a50752eb 0x5582a5061066 0x7f9eb2049bf7 0x5582a5062baa\n",
            "tcmalloc: large alloc 8699650048 bytes == 0x5583284de000 @  0x7f9eb3eb01e7 0x5582a50fb7a2 0x5582a50ea7ca 0x5582a50eb208 0x5582a5075308 0x5582a5061066 0x7f9eb2049bf7 0x5582a5062baa\n",
            "Unigram tokens 1602042 types 19156\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:229872 2:1855233664 3:3478563072 4:5565701120\n",
            "tcmalloc: large alloc 5565702144 bytes == 0x5582a69b2000 @  0x7f9eb3eb01e7 0x5582a50fb7a2 0x5582a50ea7ca 0x5582a50eb208 0x5582a50758d7 0x5582a5061066 0x7f9eb2049bf7 0x5582a5062baa\n",
            "tcmalloc: large alloc 1855234048 bytes == 0x5583f25d2000 @  0x7f9eb3eb01e7 0x5582a50fb7a2 0x5582a50ea7ca 0x5582a50eb208 0x5582a5075cdd 0x5582a5061066 0x7f9eb2049bf7 0x5582a5062baa\n",
            "tcmalloc: large alloc 3478568960 bytes == 0x55852f630000 @  0x7f9eb3eb01e7 0x5582a50fb7a2 0x5582a50ea7ca 0x5582a50eb208 0x5582a5075cdd 0x5582a5061066 0x7f9eb2049bf7 0x5582a5062baa\n",
            "Statistics:\n",
            "1 19156 D1=0.588857 D2=1.0348 D3+=1.3388\n",
            "2 231267 D1=0.722265 D2=1.09097 D3+=1.44737\n",
            "3 617624 D1=0.821472 D2=1.14168 D3+=1.40217\n",
            "4 932153 D1=0.863174 D2=1.12888 D3+=1.29333\n",
            "Memory estimate for binary LM:\n",
            "type       kB\n",
            "probing 36767 assuming -p 1.5\n",
            "probing 41816 assuming -r models -p 1.5\n",
            "trie    15838 without quantization\n",
            "trie     8356 assuming -q 8 -b 8 quantization \n",
            "trie    14567 assuming -a 22 array pointer compression\n",
            "trie     7085 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:229872 2:3700272 3:12352480 4:22371672\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:229872 2:3700272 3:12352480 4:22371672\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:14385980 kB\tVmRSS:2219112 kB\tRSSMax:2219192 kB\tuser:1.91701\tsys:1.20924\tCPU:3.12627\treal:3.31796\n",
            "Reading models/pchat_4.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "SUCCESS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYI6pw3zoixn"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "### Perplexity\n",
        "\n",
        "Intuitively, a good model should assign high probabilities to sequences from the 'true' distribution that it is modeling.\n",
        "\n",
        "A common way of quantifying this is with **perplexity**, a metric inversely-proportional to the probability that the model assigns to a set of sequences, e.g. a 'test set':\n",
        "\n",
        "\\begin{align}\n",
        "\\large \\text{ppl}(p, D) &\\large\\ = 2^{-\\frac{1}{N_{total}}\\log_2 p(D)}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "where $D=\\{(w_1,\\ldots,w_{N_i})_i\\}_{i=1}^M$ is a dataset of $M$ sequences with total length $N_{\\text{total}}=\\sum_{i}N_i$.\n",
        "\n",
        "Perplexity is defined on $[1,\\infty)$, with 1 being a perfect model (assigning probability 1 to $D$), and a 'worse' model as perplexity increases.\n",
        "\n",
        "Intuitively, _perplexity measures the average rank of the true next-token, when tokens are ordered by the model's conditional probabilities_. Another intuitve interpretation of perplexity is that it measures the average number of times you would need to sample from the language model in order to receive the true next token.\n",
        "\n",
        "\n",
        "<!-- Section 1.3 of [[Chen & Goodman 1998]](https://dash.harvard.edu/bitstream/handle/1/25104739/tr-10-98.pdf?sequence=1) has a concise summary of perplexity and its motivation. !-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzOFdU7Qoixn"
      },
      "source": [
        "#### Evaluate Perplexity\n",
        "\n",
        "`kenlm` outputs log probabilities in **log base 10**. For the standard definition of perplexity we need **log base 2**. See the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqDf2yx4oixo"
      },
      "source": [
        "def perplexity_kenlm(model, sequences):\n",
        "    n_total = 0\n",
        "    logp_total = 0\n",
        "    for sequence in sequences:\n",
        "        text = ' '.join(sequence)\n",
        "        logp_total += model.score(text)\n",
        "        n_total += len(sequence) + 1  # add 1 for <eos>\n",
        "        \n",
        "    # Convert log10 to log2\n",
        "    log2p_total = logp_total / np.log10(2)\n",
        "    ppl = 2 ** (- (1.0 / n_total) * log2p_total)\n",
        "    return ppl"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "QGeSaW-doixo",
        "outputId": "66952efb-88d1-4c3b-8d5b-3e3b2865a906"
      },
      "source": [
        "print(\"=== Train ===\")\n",
        "df = pd.DataFrame([(n, perplexity_kenlm(models[n], train)) for n in [2, 3, 4]], columns=['n', 'ppl'])\n",
        "df.style.hide_index()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Train ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_8054b19a_b690_11eb_8314_0242ac1c0002\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >n</th>        <th class=\"col_heading level0 col1\" >ppl</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                                <td id=\"T_8054b19a_b690_11eb_8314_0242ac1c0002row0_col0\" class=\"data row0 col0\" >2</td>\n",
              "                        <td id=\"T_8054b19a_b690_11eb_8314_0242ac1c0002row0_col1\" class=\"data row0 col1\" >39.924842</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_8054b19a_b690_11eb_8314_0242ac1c0002row1_col0\" class=\"data row1 col0\" >3</td>\n",
              "                        <td id=\"T_8054b19a_b690_11eb_8314_0242ac1c0002row1_col1\" class=\"data row1 col1\" >15.462037</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_8054b19a_b690_11eb_8314_0242ac1c0002row2_col0\" class=\"data row2 col0\" >4</td>\n",
              "                        <td id=\"T_8054b19a_b690_11eb_8314_0242ac1c0002row2_col1\" class=\"data row2 col1\" >8.919611</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f504469e8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "RM5ch_Xjoixo",
        "outputId": "57e2ef27-4716-4c28-9f85-f88b46f4ffd4"
      },
      "source": [
        "print(\"=== Valid ===\")\n",
        "df = pd.DataFrame([(n, perplexity_kenlm(models[n], valid)) for n in [2, 3, 4]], columns=['n', 'ppl'])\n",
        "df.style.hide_index()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Valid ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_806f9eba_b690_11eb_8314_0242ac1c0002\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >n</th>        <th class=\"col_heading level0 col1\" >ppl</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                                <td id=\"T_806f9eba_b690_11eb_8314_0242ac1c0002row0_col0\" class=\"data row0 col0\" >2</td>\n",
              "                        <td id=\"T_806f9eba_b690_11eb_8314_0242ac1c0002row0_col1\" class=\"data row0 col1\" >59.187973</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_806f9eba_b690_11eb_8314_0242ac1c0002row1_col0\" class=\"data row1 col0\" >3</td>\n",
              "                        <td id=\"T_806f9eba_b690_11eb_8314_0242ac1c0002row1_col1\" class=\"data row1 col1\" >44.977117</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_806f9eba_b690_11eb_8314_0242ac1c0002row2_col0\" class=\"data row2 col0\" >4</td>\n",
              "                        <td id=\"T_806f9eba_b690_11eb_8314_0242ac1c0002row2_col1\" class=\"data row2 col1\" >43.218831</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f501ebd7dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYYVWT-poixo"
      },
      "source": [
        "#### Sequence probabilities:\n",
        "\\begin{align}\n",
        "p(w_1,\\ldots,w_T)&\\approx\\prod_{t=1}^T p(w_t|w_{t-2},w_{t-1})\\\\\n",
        "\\log p(w_1,\\ldots,w_T) &\\approx \\sum_{t=1}^T \\log p(w_t|w_{t-2},w_{t-1}).\n",
        "\\end{align}\n",
        "\n",
        "where we use log probabilities in practice to avoid a product of many small numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW_snAP6oixo",
        "outputId": "d56c53a9-bfb4-460f-b138-555b809861c6"
      },
      "source": [
        "sentences = [\n",
        "    'i like my pet dog .',\n",
        "    'i like my pet zebra .',\n",
        "    'i like my pet lion .',\n",
        "    'i live in the united states .',\n",
        "    'i live in the united states of america .'\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    print('\\n', sentence)\n",
        "    for n in [2, 3, 4]:\n",
        "        log10p = models[n].score(sentence)\n",
        "        log2p = log10p / np.log10(2)\n",
        "        print(\"n: %d\\t logp: %.3f\" % (n, log2p))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " i like my pet dog .\n",
            "n: 2\t logp: -29.216\n",
            "n: 3\t logp: -28.843\n",
            "n: 4\t logp: -29.219\n",
            "\n",
            " i like my pet zebra .\n",
            "n: 2\t logp: -32.303\n",
            "n: 3\t logp: -31.157\n",
            "n: 4\t logp: -32.101\n",
            "\n",
            " i like my pet lion .\n",
            "n: 2\t logp: -38.352\n",
            "n: 3\t logp: -41.017\n",
            "n: 4\t logp: -42.320\n",
            "\n",
            " i live in the united states .\n",
            "n: 2\t logp: -22.599\n",
            "n: 3\t logp: -20.095\n",
            "n: 4\t logp: -17.854\n",
            "\n",
            " i live in the united states of america .\n",
            "n: 2\t logp: -40.958\n",
            "n: 3\t logp: -26.627\n",
            "n: 4\t logp: -24.311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAGY2GX4Jx4I"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}